{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13iA8FaZXCnz-dYwYnwOmspjRYSjglB5d",
      "authorship_tag": "ABX9TyOcZ4lIC2ri0X+JzeYPL+ze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atilatech/atila-core-service/blob/master/notebooks/clean_and_upload_twitter_archive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TwitterBase\n",
        "\n",
        "Create a permanent database of your twitter archive.\n",
        "\n",
        "1. Upload a zip file of your twitter archive\n",
        "2. Remove private information\n",
        "3. Create and upload to s3 bucket\n",
        "4. Serve with cloudfront\n",
        "5. Redirect twitter.atila.ca/<username> -> deployed_url\n",
        "\n",
        "## Optional: Upload Zip File to Google Drive\n",
        "\n",
        "If you are running in colab, you first need to upload the file to Google Drive so that your archive can still be accessed if you restart your notebook.\n",
        "\n",
        "I recommend uploading it to your root Google drive folder and make a folder called `twitter-archive` and put the zip file in there.\n",
        "\n",
        "\n",
        "## Understand Directory Structure\n",
        "\n",
        "It helps to understand the directory structure.\n",
        "\n",
        "Create a created_by_notebook.txt file and see where it is in your repo. That will help you know where the root of the notebook is."
      ],
      "metadata": {
        "id": "TfRn1i15-fwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir twitter-archive\n",
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqVnFET6BDfG",
        "outputId": "a5ad5dae-73bd-4f7a-e624-d4e09a57275e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data  sample.txt\ttwitter-archive\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Zip File of Twitter Archive\n",
        "\n",
        "Unzipping the file will be large and take a long time if you make any mistakes so start by creating a test.txt file with some `foobar` dummy data in your Google Drive file.\n",
        "\n",
        "Move that into your notebook folder and try reading that file to verify it works.\n",
        "\n",
        "\n",
        "Then you will do the same for your main file, Unzip to the colab notebook.\n",
        "\n",
        "Tip: [Show unzip progress](https://askubuntu.com/questions/909918/how-to-show-unzip-progress)"
      ],
      "metadata": {
        "id": "Iajh26qr-zJy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfYtt5Kh-U7c",
        "outputId": "615602ef-0cf9-4d85-e546-f4a9ecd2ff99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/twitter-archive/twitter-archive-2022-12-21-tomiwa1a-2e6e0cef38e03f7ea2dfe285b39861e6572acb880b292cf95042d912c64d0651.zip \\\n",
        "    -d twitter-archive | awk 'BEGIN {ORS=\" \"} {if(NR%10==0)print \".\"}'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_archive_file_path = \"archive\""
      ],
      "metadata": {
        "id": "AAX2X_bVGsKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('twitter-archive/data/tweets.js') as dataFile:\n",
        "    tweets = dataFile.read()\n",
        "    tweets = tweets[tweets.find('[') : tweets.rfind(']')+1]\n",
        "    tweets = json.loads(tweets)\n"
      ],
      "metadata": {
        "id": "s7Ygx51XGJca"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets[0]"
      ],
      "metadata": {
        "id": "ZCjMk3zIHQg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Personal Information\n",
        "\n",
        "1. Running the Twitter archive locally we can see that Twitter archive contains the following pieces of information that we want to remove. [todo add screenshot]\n",
        "\n",
        "## How Personal Data is Stored\n",
        "\n",
        "Most of the data is stored like this:\n",
        "\n",
        "```\n",
        "window.YTD.account.part0 = [\n",
        "  {\n",
        "    \"account\" : {\n",
        "      \"email\" : \"tomia@atila.ca\",\n",
        "      \"createdVia\" : \"<oauth:NNNNNN>\",\n",
        "      \"username\" : \"tomiwa1a\",\n",
        "      \"accountId\" : \"388018813\",\n",
        "      \"createdAt\" : \"2011-10-10T01:46:39.000Z\",\n",
        "      \"accountDisplayName\" : \"Tomiwa ðŸ˜ƒ\"\n",
        "    }\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "###  Account\n",
        "Note: This is a non exhaustive list. It's based on what I can see in my own twitter profile (@tomiwa1a). Users with different accounts may have other type of personal information, which I'm not privy to seeing.\n",
        "1. General information:\n",
        "    1. Created via oAuth -> `account.js` `root[acc`\n",
        "    1. User Creation IP\n",
        "    1. email\n",
        "    1. Phone number\n",
        "    1. Age info\n",
        "    1. Email Changes\n",
        "    1. Protected History\n",
        "\n",
        "1. Profile:\n",
        "    1. None (maybe screen name changes might be considred protected private) \n",
        "\n",
        "1. Connected Applications\n",
        "\n",
        "1. Contacts\n",
        "    1. Very personal because this includes phone number of yourself and everyone in your social network\n",
        "\n",
        "1. Sessions\n",
        "\n",
        "1. Account access history\n",
        "\n",
        "\n",
        "\n",
        "### Direct Messages\n",
        "\n",
        "Everything here can be considered personal\n",
        "\n",
        "### Personalization\n",
        "\n",
        "1. Demographics\n",
        "    1. Language\n",
        "    2. Gender\n",
        "    3. Date of Birth\n",
        "    4. Age\n",
        "1. Interests\n",
        "1. Advertiser lists\n",
        "1. Location\n",
        "1. Saved Searches\n",
        "\n",
        "### Ads\n",
        "Everything here\n",
        "\n",
        "### Lists\n",
        "\n",
        "1. None (Subscribed in lists might be considered personal but we can iterate based on user feedback.)"
      ],
      "metadata": {
        "id": "2wVBPrq-HmOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Personal Data from Account\n",
        "\n",
        "1. Remove the `createdVia` field."
      ],
      "metadata": {
        "id": "sR-4aI5KLHC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import copy\n",
        "\n",
        "def sensitize_creation_info():\n",
        "\n",
        "    # load the data from file\n",
        "    with open('twitter-archive/data/account.js') as file_io:\n",
        "        file_data_str = file_io.read()\n",
        "        # get the json part of the data\n",
        "        start_replace_index = file_data_str.find('[')\n",
        "        end_replace_index = file_data_str.rfind(']')+1\n",
        "        json_file_data_str = file_data_str[start_replace_index:end_replace_index]\n",
        "        file_data = json.loads(json_file_data_str)\n",
        "    \n",
        "    # sensitize the data\n",
        "\n",
        "    sensitized_data = copy.deepcopy(file_data)\n",
        "    sensitized_data[0]['account']['createdVia'] = '<redacted>'\n",
        "    print('data: ', file_data)\n",
        "    print('sensitized_data: ', sensitized_data)\n",
        "\n",
        "    sensitized_data_str = json.dumps(sensitized_data, indent=4)\n",
        "\n",
        "    # replace the original file data with sensitized information\n",
        "    with open('twitter-archive/data/account_sensitized.js', 'w+') as file_io:\n",
        "        file_io.write(file_data_str[:start_replace_index] \n",
        "                      + sensitized_data_str + \\\n",
        "                      file_data_str[end_replace_index+1:])\n",
        "\n",
        "sensitize_creation_info()\n",
        "!cat twitter-archive/data/account_sensitized.js\n"
      ],
      "metadata": {
        "id": "JQpGT5ePUKT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalize logic to work for different account types\n",
        "\n",
        "1. We want to define a function that we can just pass a map of fields we want to sensitize and it will automatically handle the sensitization logic."
      ],
      "metadata": {
        "id": "v6-1pkgCkZV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we could make the keys be an array of files to make our code more efficient\n",
        "# however, open and closing a file even 1000 times still takes \n",
        "# less than half a second (0.309s): https://stackoverflow.com/a/11349501/5405197\n",
        "\n",
        "\n",
        "# utility for setting nested values: https://stackoverflow.com/a/69572347/5405197\n",
        "# nested_set(data_dictionary, \"user_data.phone\", \"123\")\n",
        "def nested_set(obj, path, value):\n",
        "    *path, last = path.split(\".\")\n",
        "    for bit in path:\n",
        "        obj = obj.setdefault(bit, {})\n",
        "    obj[last] = value\n",
        "\n",
        "\n",
        "def sensitize(file_name, replace_path, replace_value):\n",
        "\n",
        "    # load the data from file\n",
        "    with open(f'twitter-archive/data/{file_name}') as file_io:\n",
        "        file_data_str = file_io.read()\n",
        "        # get the json part of the data\n",
        "        start_replace_index = file_data_str.find('[')\n",
        "        end_replace_index = file_data_str.rfind(']')+1\n",
        "        json_file_data_str = file_data_str[start_replace_index:end_replace_index]\n",
        "        file_data = json.loads(json_file_data_str)\n",
        "    \n",
        "\n",
        "    \n",
        "    # if replace path is an empty string, that means\n",
        "    # replace entire json data in the javascript file\n",
        "    sensitized_data = copy.deepcopy(file_data[0])\n",
        "    if replace_path:\n",
        "        # Get the value to be replaced\n",
        "        nested_set(sensitized_data, replace_path, replace_value)\n",
        "\n",
        "        sensitized_data = [sensitized_data] # convert back into a list as part0\n",
        "    else:\n",
        "        sensitized_data = replace_value\n",
        "    # replace the original file data with sensitized information\n",
        "\n",
        "    # expects\n",
        "    sensitized_data_str = json.dumps(sensitized_data, indent=4)\n",
        "    with open(f\"twitter-archive/data/\"\n",
        "    # note the switch to double quotes \n",
        "    f\"{file_name.replace('.js', '')}_sensitized.js\", 'w+') as file_io:\n",
        "        file_io.write(file_data_str[:start_replace_index] \n",
        "                      + sensitized_data_str + \\\n",
        "                      file_data_str[end_replace_index+1:])\n",
        "\n",
        "    # use padding to make the outputs aligned so we can visually compare them\n",
        "    print('data__pad______: ', file_data)\n",
        "    print('sensitized_data: ', sensitized_data)\n",
        "    print(f'sensitized: {file_name}#{replace_path}\\n')"
      ],
      "metadata": {
        "id": "COAPfaUykYi_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitize a few fields to make sure it's working properly"
      ],
      "metadata": {
        "id": "t6xqgeMxvhib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sensitize_configs = [\n",
        "    {\n",
        "        'file_path': 'account.js',\n",
        "        'replace_path': 'account.createdVia',\n",
        "        'replace_value': '<redacted>'\n",
        "    },\n",
        "    {\n",
        "        'file_path': 'account-creation-ip.js',\n",
        "        'replace_path': 'accountCreationIp.userCreationIp',\n",
        "        'replace_value': '<redacted>'\n",
        "    }\n",
        "]\n",
        "# note config is reserved in iPython\n",
        "for config_val in sensitize_configs: \n",
        "    \n",
        "    sensitize(config_val['file_path'],\n",
        "              config_val['replace_path'],\n",
        "              config_val['replace_value'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bukqTG2kvl2h",
        "outputId": "f94a6c34-ee07-4a47-a6be-2a59fe90d2c9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data__pad______:  [{'account': {'email': 'tomiwa@atila.ca', 'createdVia': 'oauth:111111', 'username': 'tomiwa1a', 'accountId': '388018813', 'createdAt': '2011-10-10T01:46:39.000Z', 'accountDisplayName': 'Tomiwa ðŸ˜ƒ'}}]\n",
            "sensitized_data:  [{'account': {'email': 'tomiwa@atila.ca', 'createdVia': '<redacted>', 'username': 'tomiwa1a', 'accountId': '388018813', 'createdAt': '2011-10-10T01:46:39.000Z', 'accountDisplayName': 'Tomiwa ðŸ˜ƒ'}}]\n",
            "sensitized: account.js#account.createdVia\n",
            "\n",
            "data__pad______:  [{'accountCreationIp': {'accountId': '388018813', 'userCreationIp': '11.111.11.11'}}]\n",
            "sensitized_data:  [{'accountCreationIp': {'accountId': '388018813', 'userCreationIp': '<redacted>'}}]\n",
            "sensitized: account-creation-ip.js#accountCreationIp.userCreationIp\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now Define all sensitize Configs\n"
      ],
      "metadata": {
        "id": "CVE5pUfVuKqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_SENSITIZE_CONFIGS = [\n",
        "    {\n",
        "        'file_path': 'account.js',\n",
        "        'replace_path': 'account.createdVia',\n",
        "        'replace_value': '<redacted>'\n",
        "    },\n",
        "    {\n",
        "        'file_path': 'account-creation-ip.js',\n",
        "        'replace_path': 'accountCreationIp.userCreationIp',\n",
        "        'replace_value': '<redacted>'\n",
        "    },\n",
        "    {\n",
        "        'file_path': 'email-address-change.js',\n",
        "        'replace_path': '',\n",
        "        'replace_value': []\n",
        "    },\n",
        "    {\n",
        "        'file_path': 'direct-messages.js',\n",
        "        'replace_path': '',\n",
        "        'replace_value': []\n",
        "    }\n",
        "]\n",
        "# note config is reserved in iPython\n",
        "for config_val in ALL_SENSITIZE_CONFIGS: \n",
        "    \n",
        "    sensitize(config_val['file_path'],\n",
        "              config_val['replace_path'],\n",
        "              config_val['replace_value'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VZVI1osuJ-m",
        "outputId": "16036180-10e6-4055-972a-6a785e747aa7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sensitized: account.js#account.createdVia\n",
            "\n",
            "sensitized: account-creation-ip.js#accountCreationIp.userCreationIp\n",
            "\n",
            "sensitized: direct-messages.js#\n",
            "\n"
          ]
        }
      ]
    }
  ]
}