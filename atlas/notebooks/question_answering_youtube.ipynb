{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atilatech/atila-core-service/blob/add_long_form_answering/atlas/notebooks/question_answering_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NknMdCvvBYW"
      },
      "source": [
        "# Answer Questions using Youtube\n",
        "\n",
        "This notebook shows how to give long-form answers to questions using Youtube.\n",
        "\n",
        "Inspired by [Abstractive Question Answering](https://docs.pinecone.io/docs/abstractive-question-answering) and [Long Form Question Answering in Haystack](https://www.pinecone.io/learn/haystack-lfqa/).\n",
        "\n",
        "This tutorial builds on the previous tutorial, Create an Atlas service[todo add link], that showed how to index Youtube videos and return matching sections of a video given a search term. \n",
        "\n",
        "This tutorial will be covering how to take those matching sections and combine them together to generate a long-form answer.\n",
        "\n",
        "At a high-level it is a 2 step process:\n",
        "\n",
        "1. Find sentences that have the relevant sections\n",
        "\n",
        "2. Combine the sections together to form a coherent answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uzy62mbvBYY"
      },
      "source": [
        "## Get Relevant Context\n",
        "\n",
        "First we are going to send a query \"best exercises for longevity\" and it will return all the videos that are related to the topics, exercise and longevity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0S97aOcevBYY",
        "outputId": "898f6482-02a8-409f-c2d6-627d58e5733f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.1.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.6/170.6 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from pinecone-client) (4.4.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pinecone-client) (2.2.1)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.8/dist-packages (from pinecone-client) (4.64.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from pinecone-client) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.8/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.8/dist-packages (from pinecone-client) (6.0)\n",
            "Collecting loguru>=0.5.0\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.15.0)\n",
            "Installing collected packages: loguru, pinecone-client\n",
            "Successfully installed loguru-0.6.0 pinecone-client-2.1.0\n"
          ]
        }
      ],
      "source": [
        "%pip install pinecone-client requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Cf1t6xvBYZ"
      },
      "source": [
        "## Get API Keys\n",
        "\n",
        "1. You will need a [Pinecone API key (free)](https://app.pinecone.io/).\n",
        "2. Deploy [this model](https://huggingface.co/tomiwa1a/openai-whisper-endpoint) as an inference endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qfowUen4vBYZ",
        "outputId": "bd4b3281-5b39-4809-ff42-ce5a7d9c1f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter PINECONE_API_KEY··········\n",
            "Enter HUGGING_FACE_API_KEY··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "# getpass tip: https://stackoverflow.com/a/54577734/5405197\n",
        "PINECONE_API_KEY = getpass('Enter PINECONE_API_KEY')\n",
        "HUGGING_FACE_API_KEY = getpass('Enter HUGGING_FACE_API_KEY')\n",
        "# replace this with your HUGGING_FACE_ENDPOINT_URL\n",
        "HUGGING_FACE_ENDPOINT_URL = \"https://rl2hxotyspedkt19.us-east-1.aws.endpoints.huggingface.cloud\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mgcs6wfpvBYZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pinecone\n",
        "import json\n",
        "from typing import Union\n",
        "\n",
        "pinecone_index_id = \"youtube-search\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=\"us-west1-gcp\"\n",
        ")\n",
        "\n",
        "def send_encoding_request(query: Union[str, list]):\n",
        "    payload = json.dumps({\n",
        "        \"inputs\": \"\",  # inputs key is not used but our endpoint expects it\n",
        "        \"query\": query,\n",
        "    })\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {HUGGING_FACE_API_KEY}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"POST\", HUGGING_FACE_ENDPOINT_URL, headers=headers, data=payload)\n",
        "    return response.json()\n",
        "\n",
        "pinecone_index = pinecone.Index(pinecone_index_id)\n",
        "def query_model(query, video_id=\"\"):\n",
        "    encoded_query = send_encoding_request(query)\n",
        "    metadata_filter = {\"video_id\": {\"$eq\": video_id}} if video_id else None\n",
        "    vectors = encoded_query['encoded_segments'][0]['vectors']\n",
        "    return pinecone_index.query(vectors, top_k=5,\n",
        "                                include_metadata=True,\n",
        "                                filter=metadata_filter).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89_10OTIvBYZ"
      },
      "outputs": [],
      "source": [
        "query = \"best exercises for longevity\"\n",
        "results = query_model(query)\n",
        "results['matches'][3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Generator Model\n",
        "\n",
        "Next, we create our generator, which will take the given paragraphs and combine them together to give an answer.\n",
        "\n",
        "> Generators are sequence-to-sequence (Seq2Seq) models that take the query and retrieved contexts as input and use them to generate an output, the answer.\n",
        "\n",
        "[Long-Form Question-Answering](https://www.pinecone.io/learn/haystack-lfqa/#:~:text=Generators%20are%20sequence%2Dto%2Dsequence%20(Seq2Seq)%20models%20that%20take%20the%20query%20and%20retrieved%20contexts%20as%20input%20and%20use%20them%20to%20generate%20an%20output%2C%20the%20answer.)\n",
        "\n",
        "You can think of it as a model that takes a piece of text, transforms it and generates another piece of text. We will use the [bart_lfqa model](https://towardsdatascience.com/long-form-qa-beyond-eli5-an-updated-dataset-and-approach-319cb841aabb) which [can be found on huggingface](https://huggingface.co/vblagoje/bart_lfqa)."
      ],
      "metadata": {
        "id": "I9m05gX5vWxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe0HXvv1vBYa"
      },
      "outputs": [],
      "source": [
        "%pip install -U transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"vblagoje/bart_lfqa\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "oZPqa3_66yWR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, documents):\n",
        "\n",
        "    # concatenate question and support documents into BART input\n",
        "    conditioned_doc = \"<P> \" + \" <P> \".join([d for d in documents])\n",
        "    query_and_docs = \"question: {} context: {}\".format(query, conditioned_doc)\n",
        "\n",
        "    model_input = tokenizer(query_and_docs, truncation=False, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    generated_answers_encoded = model.generate(input_ids=model_input[\"input_ids\"].to(device),\n",
        "                                            attention_mask=model_input[\"attention_mask\"].to(device),\n",
        "                                            min_length=64,\n",
        "                                            max_length=256,\n",
        "                                            do_sample=False, \n",
        "                                            early_stopping=True,\n",
        "                                            num_beams=8,\n",
        "                                            temperature=1.0,\n",
        "                                            top_k=None,\n",
        "                                            top_p=None,\n",
        "                                            eos_token_id=tokenizer.eos_token_id,\n",
        "                                            no_repeat_ngram_size=3,\n",
        "                                            num_return_sequences=1)\n",
        "    answer = tokenizer.batch_decode(generated_answers_encoded, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    return answer\n",
        "# # below is the abstractive answer generated by the model\n",
        "# [\"When you heat water to"
      ],
      "metadata": {
        "id": "iNaOUADJ-K2o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is egcg\"\n",
        "context_results = query_model(query)\n",
        "\n",
        "answer_context = [sentence['metadata']['text'] for sentence in context_results['matches']]\n",
        "\n",
        "generate_answer(query, answer_context)"
      ],
      "metadata": {
        "id": "LAfswEtG_OBF",
        "outputId": "882c347e-982a-4911-a741-0162f48fec96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_and_docs question: what is egcg context: <P>  grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into  other aspects of aging. In this new study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. Cone like micro needles were loaded  with nanoparticles containing rapamycin, EGCG, or a combination. The micro needles were applied to <P>  using dissolvable micro needles loaded with brappa mice in and epi-galocatican galate or EGCG  and active ingredients in green tea. Studies have found that rapamycin, one of the most promising  general protective drugs, not only stimulates hair regrow, but can also partially reverse hair  grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into <P>  had their thick black fur restored almost completely. While untreated controls hardly showed any  hair growth at all. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting autophagy is currently thought to be  rapamycin's central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Rapamycin and EGCG. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions. In a <P>  rapamycin's central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Rapamycin and EGCG. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions. In a  separate study, scientists have released a preprint showing the long-term supplementation of  nicotinamide riboside, or NR, an NAD precursor, alleviates the progression of age-related hearing loss  in mice. Globally, age-related hearing loss is the most common sensory deficit of older people. <P>  hair growth, while EGCG groups had higher follicle density. The best results were achieved with  a combination of both. The results were dose-dependent, with moderate doses of rapamycin being the  most effective. By day 15 of the experiment, the mice on a rapamycin and EGCG combination  had their thick black fur restored almost completely. While untreated controls hardly showed any  hair growth at all. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting autophagy is currently thought to be\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Epi-Galocatican Galate or EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. In a study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. The micro needles were applied to a dissolvable micro needles loaded with brappa mice in and epi-galocatican galate  and active ingredients in Green tea. The results were dose-dependent, with moderate doses of rapamycin being the  most effective. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting Autophagy is currently thought to be the central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_results['matches'][0]"
      ],
      "metadata": {
        "id": "XRPKePsS_t6g",
        "outputId": "46e67b74-e379-4719-fdd4-c7610d969723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'GK5YNAJrRWc-t38',\n",
              " 'score': 26.6459885,\n",
              " 'values': [],\n",
              " 'sparseValues': {},\n",
              " 'metadata': {'end': 45.0,\n",
              "  'id': 'GK5YNAJrRWc-t38',\n",
              "  'length': 252.0,\n",
              "  'start': 38.0,\n",
              "  'text': ' grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into  other aspects of aging. In this new study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. Cone like micro needles were loaded  with nanoparticles containing rapamycin, EGCG, or a combination. The micro needles were applied to',\n",
              "  'thumbnail': 'https://i.ytimg.com/vi/GK5YNAJrRWc/sddefault.jpg',\n",
              "  'title': '\"Longevity Molecules\" Preserve Hair & Hearing in Mice',\n",
              "  'url': 'https://youtu.be/GK5YNAJrRWc?t=38',\n",
              "  'video_id': 'GK5YNAJrRWc',\n",
              "  'views': 1818.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLB5hHxWF6Pz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "99e086eccb441fa1228dffc6d0e819d43cb52e5c644083572317aeec389d6017"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}