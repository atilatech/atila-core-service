{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atilatech/atila-core-service/blob/add_long_form_answering/atlas/notebooks/question_answering_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NknMdCvvBYW"
      },
      "source": [
        "# Answer Questions using Youtube\n",
        "\n",
        "This notebook shows how to give long-form answers to questions using Youtube.\n",
        "\n",
        "Inspired by [Abstractive Question Answering](https://docs.pinecone.io/docs/abstractive-question-answering) and [Long Form Question Answering in Haystack](https://www.pinecone.io/learn/haystack-lfqa/).\n",
        "\n",
        "This tutorial builds on the previous tutorial, Create an Atlas service[todo add link], that showed how to index Youtube videos and return matching sections of a video given a search term. \n",
        "\n",
        "This tutorial will be covering how to take those matching sections and combine them together to generate a long-form answer.\n",
        "\n",
        "At a high-level it is a 2 step process:\n",
        "\n",
        "1. Find sentences that have the relevant sections\n",
        "\n",
        "2. Combine the sections together to form a coherent answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uzy62mbvBYY"
      },
      "source": [
        "## Get Relevant Context\n",
        "\n",
        "First we are going to send a query \"best exercises for longevity\" and it will return all the videos that are related to the topics, exercise and longevity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S97aOcevBYY"
      },
      "outputs": [],
      "source": [
        "%pip install pinecone-client requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Cf1t6xvBYZ"
      },
      "source": [
        "## Get API Keys\n",
        "\n",
        "1. You will need a [Pinecone API key (free)](https://app.pinecone.io/).\n",
        "2. Deploy [this model](https://huggingface.co/tomiwa1a/openai-whisper-endpoint) as an inference endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfowUen4vBYZ"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "# getpass tip: https://stackoverflow.com/a/54577734/5405197\n",
        "PINECONE_API_KEY = getpass('Enter PINECONE_API_KEY')\n",
        "HUGGING_FACE_API_KEY = getpass('Enter HUGGING_FACE_API_KEY')\n",
        "# replace this with your HUGGING_FACE_ENDPOINT_URL\n",
        "HUGGING_FACE_ENDPOINT_URL = \"https://rl2hxotyspedkt19.us-east-1.aws.endpoints.huggingface.cloud\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mgcs6wfpvBYZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pinecone\n",
        "import json\n",
        "from typing import Union\n",
        "\n",
        "pinecone_index_id = \"youtube-search\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=\"us-west1-gcp\"\n",
        ")\n",
        "\n",
        "def send_encoding_request(query: Union[str, list]):\n",
        "    payload = json.dumps({\n",
        "        \"inputs\": \"\",  # inputs key is not used but our endpoint expects it\n",
        "        \"query\": query,\n",
        "    })\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {HUGGING_FACE_API_KEY}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"POST\", HUGGING_FACE_ENDPOINT_URL, headers=headers, data=payload)\n",
        "    return response.json()\n",
        "\n",
        "pinecone_index = pinecone.Index(pinecone_index_id)\n",
        "def query_model(query, video_id=\"\"):\n",
        "    encoded_query = send_encoding_request(query)\n",
        "    metadata_filter = {\"video_id\": {\"$eq\": video_id}} if video_id else None\n",
        "    vectors = encoded_query['encoded_segments'][0]['vectors']\n",
        "    return pinecone_index.query(vectors, top_k=5,\n",
        "                                include_metadata=True,\n",
        "                                filter=metadata_filter).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89_10OTIvBYZ"
      },
      "outputs": [],
      "source": [
        "query = \"best exercises for longevity\"\n",
        "results = query_model(query)\n",
        "results['matches'][3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Generator Model\n",
        "\n",
        "Next, we create our generator, which will take the given paragraphs and combine them together to give an answer.\n",
        "\n",
        "> Generators are sequence-to-sequence (Seq2Seq) models that take the query and retrieved contexts as input and use them to generate an output, the answer.\n",
        "\n",
        "[Long-Form Question-Answering](https://www.pinecone.io/learn/haystack-lfqa/#:~:text=Generators%20are%20sequence%2Dto%2Dsequence%20(Seq2Seq)%20models%20that%20take%20the%20query%20and%20retrieved%20contexts%20as%20input%20and%20use%20them%20to%20generate%20an%20output%2C%20the%20answer.)\n",
        "\n",
        "You can think of it as a model that takes a piece of text, transforms it and generates another piece of text. We will use the [bart_lfqa model](https://towardsdatascience.com/long-form-qa-beyond-eli5-an-updated-dataset-and-approach-319cb841aabb) which [can be found on huggingface](https://huggingface.co/vblagoje/bart_lfqa)."
      ],
      "metadata": {
        "id": "I9m05gX5vWxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe0HXvv1vBYa"
      },
      "outputs": [],
      "source": [
        "%pip install -U transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"vblagoje/bart_lfqa\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "oZPqa3_66yWR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, documents):\n",
        "\n",
        "    # concatenate question and support documents into BART input\n",
        "    conditioned_doc = \"<P> \" + \" <P> \".join([d for d in documents])\n",
        "    query_and_docs = \"question: {} context: {}\".format(query, conditioned_doc)\n",
        "\n",
        "    model_input = tokenizer(query_and_docs, truncation=False, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    generated_answers_encoded = model.generate(input_ids=model_input[\"input_ids\"].to(device),\n",
        "                                            attention_mask=model_input[\"attention_mask\"].to(device),\n",
        "                                            min_length=64,\n",
        "                                            max_length=256,\n",
        "                                            do_sample=False, \n",
        "                                            early_stopping=True,\n",
        "                                            num_beams=8,\n",
        "                                            temperature=1.0,\n",
        "                                            top_k=None,\n",
        "                                            top_p=None,\n",
        "                                            eos_token_id=tokenizer.eos_token_id,\n",
        "                                            no_repeat_ngram_size=3,\n",
        "                                            num_return_sequences=1)\n",
        "    answer = tokenizer.batch_decode(generated_answers_encoded, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    return answer\n",
        "# # below is the abstractive answer generated by the model\n",
        "# [\"When you heat water to"
      ],
      "metadata": {
        "id": "iNaOUADJ-K2o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is egcg\"\n",
        "context_results = query_model(query)\n",
        "\n",
        "answer_context = [sentence['metadata']['text'] for sentence in context_results['matches']]\n",
        "\n",
        "generate_answer(query, answer_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAfswEtG_OBF",
        "outputId": "882c347e-982a-4911-a741-0162f48fec96"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_and_docs question: what is egcg context: <P>  grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into  other aspects of aging. In this new study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. Cone like micro needles were loaded  with nanoparticles containing rapamycin, EGCG, or a combination. The micro needles were applied to <P>  using dissolvable micro needles loaded with brappa mice in and epi-galocatican galate or EGCG  and active ingredients in green tea. Studies have found that rapamycin, one of the most promising  general protective drugs, not only stimulates hair regrow, but can also partially reverse hair  grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into <P>  had their thick black fur restored almost completely. While untreated controls hardly showed any  hair growth at all. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting autophagy is currently thought to be  rapamycin's central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Rapamycin and EGCG. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions. In a <P>  rapamycin's central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Rapamycin and EGCG. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions. In a  separate study, scientists have released a preprint showing the long-term supplementation of  nicotinamide riboside, or NR, an NAD precursor, alleviates the progression of age-related hearing loss  in mice. Globally, age-related hearing loss is the most common sensory deficit of older people. <P>  hair growth, while EGCG groups had higher follicle density. The best results were achieved with  a combination of both. The results were dose-dependent, with moderate doses of rapamycin being the  most effective. By day 15 of the experiment, the mice on a rapamycin and EGCG combination  had their thick black fur restored almost completely. While untreated controls hardly showed any  hair growth at all. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting autophagy is currently thought to be\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Epi-Galocatican Galate or EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. In a study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. The micro needles were applied to a dissolvable micro needles loaded with brappa mice in and epi-galocatican galate  and active ingredients in Green tea. The results were dose-dependent, with moderate doses of rapamycin being the  most effective. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting Autophagy is currently thought to be the central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_results['matches'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRPKePsS_t6g",
        "outputId": "46e67b74-e379-4719-fdd4-c7610d969723"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'GK5YNAJrRWc-t38',\n",
              " 'score': 26.6459885,\n",
              " 'values': [],\n",
              " 'sparseValues': {},\n",
              " 'metadata': {'end': 45.0,\n",
              "  'id': 'GK5YNAJrRWc-t38',\n",
              "  'length': 252.0,\n",
              "  'start': 38.0,\n",
              "  'text': ' grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into  other aspects of aging. In this new study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. Cone like micro needles were loaded  with nanoparticles containing rapamycin, EGCG, or a combination. The micro needles were applied to',\n",
              "  'thumbnail': 'https://i.ytimg.com/vi/GK5YNAJrRWc/sddefault.jpg',\n",
              "  'title': '\"Longevity Molecules\" Preserve Hair & Hearing in Mice',\n",
              "  'url': 'https://youtu.be/GK5YNAJrRWc?t=38',\n",
              "  'video_id': 'GK5YNAJrRWc',\n",
              "  'views': 1818.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy to Huggingface\n",
        "\n",
        "Take this function and combine it with the functions in the previous step and create an endpoint handler that can be used in Huggingface."
      ],
      "metadata": {
        "id": "QvKfpeocK7Lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "0C-RQymGLLH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence_transformers pytube\n",
        "\n",
        "# optional install pytorch so you can use a gpu for faster transcription\n",
        "# command below is for Linux. See instructions for mac and windows: https://pytorch.org/get-started/locally/\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!apt install ffmpeg # https://stackoverflow.com/questions/51856340/how-to-install-package-ffmpeg-in-google-colab"
      ],
      "metadata": {
        "id": "H8dTQB80LKTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import whisper\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import pytube\n",
        "import time\n",
        "\n",
        "\n",
        "class EndpointHandler():\n",
        "    # load the model\n",
        "    WHISPER_MODEL_NAME = \"tiny.en\"\n",
        "    SENTENCE_TRANSFORMER_MODEL_NAME = \"multi-qa-mpnet-base-dot-v1\"\n",
        "    QUESTION_ANSWER_MODEL_NAME = \"vblagoje/bart_lfqa\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def __init__(self, path=\"\"):\n",
        "\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f'whisper and question_answer_model will use: {device}')\n",
        "\n",
        "        t0 = time.time()\n",
        "        self.whisper_model = whisper.load_model(self.WHISPER_MODEL_NAME).to(device)\n",
        "        t1 = time.time()\n",
        "\n",
        "        total = t1 - t0\n",
        "        print(f'Finished loading whisper_model in {total} seconds')\n",
        "\n",
        "        t0 = time.time()\n",
        "        self.sentence_transformer_model = SentenceTransformer(self.SENTENCE_TRANSFORMER_MODEL_NAME)\n",
        "        t1 = time.time()\n",
        "\n",
        "        total = t1 - t0\n",
        "        print(f'Finished loading sentence_transformer_model in {total} seconds')\n",
        "        \n",
        "        self.question_answer_tokenizer = AutoTokenizer.from_pretrained(self.QUESTION_ANSWER_MODEL_NAME)\n",
        "        t0 = time.time()\n",
        "        self.question_answer_model = AutoModelForSeq2SeqLM.from_pretrained(self.QUESTION_ANSWER_MODEL_NAME).to(device)\n",
        "        t1 = time.time()\n",
        "        total = t1 - t0\n",
        "        print(f'Finished loading question_answer_model in {total} seconds')\n",
        "\n",
        "    def __call__(self, data: Dict[str, str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (:obj:):\n",
        "                includes the URL to video for transcription\n",
        "        Return:\n",
        "            A :obj:`dict`:. transcribed dict\n",
        "        \"\"\"\n",
        "        # process input\n",
        "        print('data', data)\n",
        "\n",
        "        if \"inputs\" not in data:\n",
        "            raise Exception(f\"data is missing 'inputs' key which  EndpointHandler expects. Received: {data}\"\n",
        "                            f\" See: https://huggingface.co/docs/inference-endpoints/guides/custom_handler#2-create-endpointhandler-cp\")\n",
        "        video_url = data.pop(\"video_url\", None)\n",
        "        query = data.pop(\"query\", None)\n",
        "        long_form_answer = data.pop(\"long_form_answer\", None)\n",
        "        encoded_segments = {}\n",
        "        if video_url:\n",
        "            video_with_transcript = self.transcribe_video(video_url)\n",
        "            video_with_transcript['transcript']['transcription_source'] = f\"whisper_{self.WHISPER_MODEL_NAME}\"\n",
        "            encode_transcript = data.pop(\"encode_transcript\", True)\n",
        "            if encode_transcript:\n",
        "                encoded_segments = self.combine_transcripts(video_with_transcript)\n",
        "                encoded_segments = {\n",
        "                    \"encoded_segments\": self.encode_sentences(encoded_segments)\n",
        "                }\n",
        "            return {\n",
        "                **video_with_transcript,\n",
        "                **encoded_segments\n",
        "            }\n",
        "        elif query:\n",
        "            if long_form_answer:\n",
        "                context = data.pop(\"context\", None)\n",
        "                answer = self.generate_answer(query, context)\n",
        "                response = {\n",
        "                    \"answer\": answer\n",
        "                }\n",
        "\n",
        "                return response\n",
        "            else:\n",
        "                query = [{\"text\": query, \"id\": \"\"}] if isinstance(query, str) else query\n",
        "                encoded_segments = self.encode_sentences(query)\n",
        "\n",
        "                response = {\n",
        "                    \"encoded_segments\": encoded_segments\n",
        "                }\n",
        "\n",
        "                return response\n",
        "\n",
        "        else:\n",
        "            return {\n",
        "                \"error\": \"'video_url' or 'query' must be provided\"\n",
        "            }\n",
        "\n",
        "    def transcribe_video(self, video_url):\n",
        "        decode_options = {\n",
        "            # Set language to None to support multilingual,\n",
        "            # but it will take longer to process while it detects the language.\n",
        "            # Realized this by running in verbose mode and seeing how much time\n",
        "            # was spent on the decoding language step\n",
        "            \"language\": \"en\",\n",
        "            \"verbose\": True\n",
        "        }\n",
        "        yt = pytube.YouTube(video_url)\n",
        "        video_info = {\n",
        "            'id': yt.video_id,\n",
        "            'thumbnail': yt.thumbnail_url,\n",
        "            'title': yt.title,\n",
        "            'views': yt.views,\n",
        "            'length': yt.length,\n",
        "            # Althhough, this might seem redundant since we already have id\n",
        "            # but it allows the link to the video be accessed in 1-click in the API response\n",
        "            'url': f\"https://www.youtube.com/watch?v={yt.video_id}\"\n",
        "        }\n",
        "        stream = yt.streams.filter(only_audio=True)[0]\n",
        "        path_to_audio = f\"{yt.video_id}.mp3\"\n",
        "        stream.download(filename=path_to_audio)\n",
        "        t0 = time.time()\n",
        "        transcript = self.whisper_model.transcribe(path_to_audio, **decode_options)\n",
        "        t1 = time.time()\n",
        "        for segment in transcript['segments']:\n",
        "            # Remove the tokens array, it makes the response too verbose\n",
        "            segment.pop('tokens', None)\n",
        "\n",
        "        total = t1 - t0\n",
        "        print(f'Finished transcription in {total} seconds')\n",
        "\n",
        "        # postprocess the prediction\n",
        "        return {\"transcript\": transcript, 'video': video_info}\n",
        "\n",
        "    def encode_sentences(self, transcripts, batch_size=64):\n",
        "        \"\"\"\n",
        "        Encoding all of our segments at once or storing them locally would require too much compute or memory.\n",
        "        So we do it in batches of 64\n",
        "        :param transcripts:\n",
        "        :param batch_size:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # loop through in batches of 64\n",
        "        all_batches = []\n",
        "        for i in tqdm(range(0, len(transcripts), batch_size)):\n",
        "            # find end position of batch (for when we hit end of data)\n",
        "            i_end = min(len(transcripts), i + batch_size)\n",
        "            # extract the metadata like text, start/end positions, etc\n",
        "            batch_meta = [{\n",
        "                **row\n",
        "            } for row in transcripts[i:i_end]]\n",
        "            # extract only text to be encoded by embedding model\n",
        "            batch_text = [\n",
        "                row['text'] for row in batch_meta\n",
        "            ]\n",
        "            # create the embedding vectors\n",
        "            batch_vectors = self.sentence_transformer_model.encode(batch_text).tolist()\n",
        "\n",
        "            batch_details = [\n",
        "                {\n",
        "                    **batch_meta[x],\n",
        "                    'vectors': batch_vectors[x]\n",
        "                } for x in range(0, len(batch_meta))\n",
        "            ]\n",
        "            all_batches.extend(batch_details)\n",
        "\n",
        "        return all_batches\n",
        "\n",
        "    def generate_answer(self, query, documents):\n",
        "\n",
        "        # concatenate question and support documents into BART input\n",
        "        conditioned_doc = \"<P> \" + \" <P> \".join([d for d in documents])\n",
        "        query_and_docs = \"question: {} context: {}\".format(query, conditioned_doc)\n",
        "\n",
        "        model_input = self.question_answer_tokenizer(query_and_docs, truncation=False, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "        generated_answers_encoded = self.question_answer_model.generate(input_ids=model_input[\"input_ids\"].to(self.device),\n",
        "                                                attention_mask=model_input[\"attention_mask\"].to(self.device),\n",
        "                                                min_length=64,\n",
        "                                                max_length=256,\n",
        "                                                do_sample=False, \n",
        "                                                early_stopping=True,\n",
        "                                                num_beams=8,\n",
        "                                                temperature=1.0,\n",
        "                                                top_k=None,\n",
        "                                                top_p=None,\n",
        "                                                eos_token_id=self.question_answer_tokenizer.eos_token_id,\n",
        "                                                no_repeat_ngram_size=3,\n",
        "                                                num_return_sequences=1)\n",
        "        answer = self.question_answer_tokenizer.batch_decode(generated_answers_encoded, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "        return answer\n",
        "\n",
        "    @staticmethod\n",
        "    def combine_transcripts(video, window=6, stride=3):\n",
        "        \"\"\"\n",
        "\n",
        "        :param video:\n",
        "        :param window: number of sentences to combine\n",
        "        :param stride: number of sentences to 'stride' over, used to create overlap\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_transcript_segments = []\n",
        "\n",
        "        video_info = video['video']\n",
        "        transcript_segments = video['transcript']['segments']\n",
        "        for i in tqdm(range(0, len(transcript_segments), stride)):\n",
        "            i_end = min(len(transcript_segments), i + window)\n",
        "            text = ' '.join(transcript['text']\n",
        "                            for transcript in\n",
        "                            transcript_segments[i:i_end])\n",
        "            # TODO: Should int (float to seconds) conversion happen at the API level?\n",
        "            start = int(transcript_segments[i]['start'])\n",
        "            end = int(transcript_segments[i]['end'])\n",
        "            new_transcript_segments.append({\n",
        "                **video_info,\n",
        "                **{\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'title': video_info['title'],\n",
        "                    'text': text,\n",
        "                    'id': f\"{video_info['id']}-t{start}\",\n",
        "                    'url': f\"https://youtu.be/{video_info['id']}?t={start}\",\n",
        "                    'video_id': video_info['id'],\n",
        "                }\n",
        "            })\n",
        "        return new_transcript_segments\n"
      ],
      "metadata": {
        "id": "LLB5hHxWF6Pz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_handler = EndpointHandler(path=\"\")"
      ],
      "metadata": {
        "id": "YUmHNGBHMUS7",
        "outputId": "e9eb1ecc-4734-4cc3-b2da-035054446769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper and question_answer_model will use: cuda\n",
            "Finished loading whisper_model in 0.6368415355682373 seconds\n",
            "Finished loading sentence_transformer_model in 0.9580769538879395 seconds\n",
            "Finished loading question_answer_model in 4.88532018661499 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is egcg\"\n",
        "context_results = query_model(query)\n",
        "\n",
        "answer_context = [sentence['metadata']['text'] for sentence in context_results['matches']]\n",
        "\n",
        "payload = {\"query\": \"what is egcg\", \"inputs\": \"\",\n",
        "           'long_form_answer': True, 'context': answer_context}\n",
        "payload_pred=my_handler(payload)\n",
        "payload_pred"
      ],
      "metadata": {
        "id": "HFVRszSyMm9Y",
        "outputId": "5623636d-0e72-464a-849c-74bac1c05e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data {'query': 'what is egcg', 'inputs': '', 'long_form_answer': True, 'context': [' grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into  other aspects of aging. In this new study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. Cone like micro needles were loaded  with nanoparticles containing rapamycin, EGCG, or a combination. The micro needles were applied to', ' using dissolvable micro needles loaded with brappa mice in and epi-galocatican galate or EGCG  and active ingredients in green tea. Studies have found that rapamycin, one of the most promising  general protective drugs, not only stimulates hair regrow, but can also partially reverse hair  grain. EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. Combating hair loss is not just about looks,  understanding the mechanisms of senescent alopecia and ways to reverse it can provide insights into', \" had their thick black fur restored almost completely. While untreated controls hardly showed any  hair growth at all. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting autophagy is currently thought to be  rapamycin's central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Rapamycin and EGCG. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions. In a\", \" rapamycin's central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Rapamycin and EGCG. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions. In a  separate study, scientists have released a preprint showing the long-term supplementation of  nicotinamide riboside, or NR, an NAD precursor, alleviates the progression of age-related hearing loss  in mice. Globally, age-related hearing loss is the most common sensory deficit of older people.\", ' hair growth, while EGCG groups had higher follicle density. The best results were achieved with  a combination of both. The results were dose-dependent, with moderate doses of rapamycin being the  most effective. By day 15 of the experiment, the mice on a rapamycin and EGCG combination  had their thick black fur restored almost completely. While untreated controls hardly showed any  hair growth at all. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting autophagy is currently thought to be']}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': ['Epi-Galocatican Galate or EGCG is a polyphenol found in green tea and a potent antioxidant that has shown effectiveness  against various conditions, including androgenic alopecia. In a study, the researchers used an emerging micro needle technology  to deliver drugs directly to the inner layers of the skin. The micro needles were applied to a dissolvable micro needles loaded with brappa mice in and epi-galocatican galate  and active ingredients in Green tea. The results were dose-dependent, with moderate doses of rapamycin being the  most effective. The researchers also confirmed that the treatment resulted in increased  autophagy in follicular regions, and promoting Autophagy is currently thought to be the central mechanism of action. This study reiterates the health potential of two  molecules popular in the longevity field. Additionally, this micro needle-based  drug delivery method could potentially be used to treat various other skin conditions.']}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload = {\"video_url\": \"https://www.youtube.com/watch?v=ciKdF97JWpU\", 'inputs': ''} # Jimmy Butler Reveals What Made Him Leave the Philadelphia 76ers | The JJ Redick Podcast | The Ringer\n",
        "\n",
        "\n",
        "# # test the handler\n",
        "payload_pred=my_handler(payload) # note this line might give 'AttributeError: 'OutStream' object has no attribute 'buffer'' error\n",
        "payload_pred "
      ],
      "metadata": {
        "id": "ASCUnfMZQKYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payload = {\"query\": \"basketball\", 'inputs': ''} # Jimmy Butler Reveals What Made Him Leave the Philadelphia 76ers | The JJ Redick Podcast | The Ringer\n",
        "\n",
        "\n",
        "# # test the handler\n",
        "payload_pred=my_handler(payload)\n",
        "payload_pred"
      ],
      "metadata": {
        "id": "SshMAveJPglX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "99e086eccb441fa1228dffc6d0e819d43cb52e5c644083572317aeec389d6017"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}